# 웹 크롤러 설계
- 이용되는 곳 : 검색 엔진 인덱싱, 웹 아카이빙, 웹 마이닝, 웹 모니터링
- 개략적 규모 추정 : 매달 10억개 다운로드, QPS = 10억 대략 초당 400페이지, Peak QPS는 곱하기 2배하면 800, 평균 페이지당 500k라 가정할때 10억 페이지는 500TB, 5년간 보관 기준시 30PB.
- 시작 URL 집합 -> 미수집 URL 저장소 -> HTML 다운로더 -> 도메인 이름 변환기 -> 컨텐츠 파서 -> 중복 컨텐츠?(컨텐츠 저장소) -> URL 추출기 -> URL 필터 -> 이미 방문한 URL? -> URL 저장소 & 미수집 URL로 이동.
- 탐색론 : DPF(깊이 우선 탐색), BFS(너비 우선 탐색) 추천은 BFS.
- 예의 : Impolite(무례한) 짓은 하지 말자. DoS를 하지 말아라.
- 우선순위 : 어떤 Site가 중요한지에 대한 판단은 페이지랭크, 트래픽 양, 갱신 빈도 등 다양한 척도를 사용.
- 신선도 : 웹 페이지의 변경 이력 활용, 우선순위를 활요하여, 중요한 페이지는 좀 더 자주 재수집.
- Robots.txt : 웹 크롤러에게 수집 허용 및 불가에 대한 내용이 담겨있음.
  - 예시 : https://www.amazon.com/robots.txt
- 성능 최적화 : 분산 크롤링, 도메인 변환 결과 캐시, 지역성, 짧은 타임아웃
- 안정성 : 안정 해시, 크롤링 상태 및 수집 데이터 저장, 예외 처리, 데이터 검증
- 확장성 : 새로운 형태의 콘텐츠를 지원하기 위해 분리하여 추가하는 확장모듈을 붙이는 방식
  - 예시 : PNG 다운로더, URL 추출기, 웹 모니터
- 문제 있는 콘텐츠 감지 및 회피 : 중복 콘텐츠, 거미 덫, 데이터 노이즈


## 논의 주제
- 왜 Peak QPS를 곱하기 2로 했을까요? Peak 기준은 뭘로 잡는게 좋을까요?
