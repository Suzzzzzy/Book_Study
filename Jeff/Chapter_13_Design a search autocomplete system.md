## CHAPTER 13: DESIGN A SEARCH AUTOCOMPLETE SYSTEM

```
논의내용)
실시간 검색어 자동완성의 경우 트라이라는 트리 형태의 자료구조를 사용한다는 걸 알게 되서 배우면서 책을 읽 것 같습니다.

책에 마무리 단계에서 면접관이 하는 질문 중에 다국어 지원의 경우 유니코드를 쓰는 것 까지는 좋은데 만약 언어별로 다룬다고 하면 별도의 트라이를 가져가는게 더 효율적일까요? 예로 한국어, 중국어, 일본어 검색을 지원한다고 하면 트라이가 3개가 필요할지 아니면 하나의 트라이에서 유니코드만 보고 빈도 계산만 해서 해줘도 될지 궁금하네요.
```

검색어 자동 완성은 다음 단어들로 사용한다.
autocomplete, typeahead, search-as-you-type, incremental search

아래 그림은 구글 검색창에 dinner를 검색하면 볼 수 있는 자동완성 검색어들이다.

<img width="447" alt="image" src="https://github.com/jongfeel/BookReview/assets/17442457/2afcb0f8-e27d-45d3-9e58-2cf85da114c5">

### 1단계 문제 이해 및 설계 범위 확정

#### 요구사항

- 빠른 응답 속도: 검색어를 입력하면서 자동완성 검색어도 충분히 빨리 표시되어야 한다. 페이스북의 경우는 응답속도는 100밀리초 이내로 한다.
- 연관성: 자동완성되는 검색어는 입력 단어와 연관이 있어야 한다.
- 정렬: 시스템의 계산 결과는 인기도 등의 순위 모델(ranking model)에 의해 정렬되어 있어야 한다.
- 규모 확장성: 시스템은 많은 트래픽을 감당할 수 있도록 확장 가능해야 한다.
- 고가용성: 시스템의 일부에 장애가 발생하거나, 느려지거나, 예상치 못한 네트워크 문제가 생겨도 시스템은 계속 사용 가능해야 한다.

#### 개략적 규모 추정

- 일간 능동 사용자(DAU)는 천만 명으로 가정
- 매일 10건의 검색을 수행한다고 가정
- 질의할 때마다 평균적으로 20바이트의 데이터를 입력한다고 가정
  - 인코딩 방식이 ASCII라면 1문자 = 1바이트이다.
  - 평균 4개 단어로 이루어진다고 가정하며, 단어는 평균적으로 다섯 글자로 구성된다고 가정
  - 그러면 4 x 5 = 20 바이트이다.
- 검색창에 글자를 입력할 때마다 클라이언트는 검색어 자동완성 백엔드에 요청을 보낸다. 평균 1회 검색하면 20건의 요청이 전달된다. 검색창에 dinner를 입력하면 아래 6개의 요청이 순차적으로 백엔드에 전송된다.

search?q=d
search?q=di
search?q=din
search?q=dinn
search?q=dinne
search?q=dinner

- 초당 24000건의 질의(QPS)가 발생 = 10,000,000 사용자 x 10 질의 / 일 x 20자 / 24시간 / 3600초
- 최대 QPS는 QPS x 2 = 약 48000
- 질의 중 20%는 신규 검색어라고 가정하면 대략 0.4GB 이다. = 10,000,000 사용자 x 10 질의 / 일 x 20자 x 20%. 매일 0.4GB의 신규 데이터가 시스템에 추가된다.

### 2단계 개략적 설계안 제시 및 동의 구하기

개략적으로 시스템은 두 부분으로 나뉜다.

- 데이터 수집 서비스(data gathering service): 사용자가 입력한 질의를 실시간으로 수집하는 시스템이다. 데이터가 많은 애플리케이션에 실시간 시스템은 적합하지 않지만 초기 설계에 진행하고 상세 설계에서 변경한다.
- 질의 서비스(query service): 주어진 질의에 다섯 개의 인기 검색어를 정렬해서 주는 서비스이다.

#### 데이터 수집 서비스

질의문과 사용빈도를 저장하는 빈도 테이블(frequency table)이 있다고 가정한다.
사용자가 'twitch', 'twitter', 'twitter', 'twillo' 순서대로 검색하면 다음과 같이 상태가 변한다.

<img width="454" alt="image" src="https://github.com/jongfeel/BookReview/assets/17442457/f153e54b-1640-4fab-8589-22c9e450a85f">

#### 질의 서비스

아래 빈도 테이블에서

- query: 질의문을 저장하는 필드
- frequency: 질의문이 사용된 빈도를 저장하는 필드

| query | frequency |
|--------|------------|
| Twitter | 35 |
| twitch | 29 |
| twilight | 25 |
| twin peak | 21 |
| twitch prime | 18 |
| twitter search | 14 |
| twillo | 10 |
| twin peak sf | 8 |

이 상태에서 사용자가 "tw"를 검색창에 입력하면 top5 자동완성 검색어는 다음과 같이 표시되어야 한다.

<img width="197" alt="image" src="https://github.com/jongfeel/BookReview/assets/17442457/302a7f46-ef72-4a0c-8281-46f289a31c13">

가장 많이 사용된 5개 검색어 top5는 아래 SQL 문을 사용해 계산할 수 있다.

``` SQL
SELECT * FROM frequency_table
WHERE query Like `prefix%`
ORDER BY frequency DESC
LIMIT 5
```

데이터가 적으면 괜찮은데 데이터가 많아지면 데이터베이스 병목이 생긴다. 상세 설계안을 통해 이 문제를 해결한다.

### 3단계 상세 설계

아래 컴포넌트들을 상세 설계하고 최적화 방안을 논의한다.

- 트라이(trie) 자료구조
- 데이터 수집 서비스
- 질의 서비스
- 규모 확장이 가능한 저장소
- 트라이 연산

#### 트라이 자료구조

관계형 데이터베이스에서 인기 있는 다섯 개 질의문을 골라내는 방법은 효율적이지 않다. 이 문제는 트라이(trie, prefix tree)를 사용해 해결한다.
여기서는 트라이가 무엇인지 간단하게 살펴보고, 트라이를 어떻게 최적화하면 응답 시간을 줄일 수 있는지 알아본다.

트라이는 문자열들을 간략하게 저장할 수 있는 자료구조다. 트라이라는 이름은 "retrieval" 이라는 단어에서 왔는데, 문자열을 꺼내는 연산에 초점을 맞춰 설계된 자료 구조이다. 트라이 자료구조의 핵심 아이디어는 다음과 같다.

- 트라이는 트리 형태의 자료구조다.
- 이 트리의 루트 노드는 빈 문자열을 나타낸다.
- 각 노드는 글자(character) 하나를 저장하며, 26개(해당 글자 다음에 등장할 수 있는 모든 글자 개수)의 자식 노드를 가진다.
- 각 트리 노드는 하나의 단어, 또는 접두어 문자열(prefix string)을 나타낸다.

아래 그림은 질의어 'tree', 'try', 'true', 'toy', 'wish', 'win'이 보관된 트라이다.

<img width="462" alt="image" src="https://github.com/jongfeel/BookReview/assets/17442457/e401c93d-27f4-402f-aba9-76ad9becd887">

기본 트라이 자료구조는 노드에 문자들을 저장한다. 이용 빈도에 따라 정렬된 결과를 내놓기 위해서는 노드에 빈도 정보까지 저장할 필요가 있다.

| query | frequency |
|--------|------------|
| tree | 10 |
| try | 29 |
| true | 35 |
| toy | 14 |
| wish | 25 |
| win | 50 |

위와 같은 빈도 테이블이 있을 때 이 정보를 트라이 노드에 저장하면 아래 그림처럼 된다.

<img width="389" alt="image" src="https://github.com/jongfeel/BookReview/assets/17442457/a55409f5-c850-48ec-8f21-cb83e14f27c4">

검색어 자동 완성 구현 이전에 용어 정의를 한다.

- p: 접두어(prefix)의 길이
- n: 트라이 안에 있는 노드 개수
- c: 주어진 노드의 자식 노드 개수

가장 많이 사용된 질의어 k는 다음과 같이 찾을 수 있다.

- 해당 접두어를 표현하는 노드를 찾는다. 시간 복잡도는 O(p) 이다.
- 해당 노드부터 시작하는 하위 트리를 탐색하여 모든 유효 노드를 찾는다. 유효한 검색 문자열을 구성하는 노드가 유효 노드다. 시간 복잡도는 O(c)이다.
- 유효 노드들을 정렬하여 가장 인기 있는 검색어 k개를 찾는다. 시간 복잡도는 O(c log c) 이다.

아래 그림의 예제에서 k = 2이고 검색창에 'be'를 입력했다고 하면 알고리즘은 다음과 같이 동작한다.

1. 접두어 노드 'be'를 찾는다.
2. 해당 노드부터 시작하는 하위 트리를 탐색하여 모든 유효 노드를 찾는다. [beer:10], [best:35], [bet: 29]가 유효 노드다.
3. 유효 노드를 정렬하여 2개를 골라낸다. [best:35], [bet: 29]가 접두어 'be'에 대해 검색된 2개의 인기 검색어다.

<img width="406" alt="image" src="https://github.com/jongfeel/BookReview/assets/17442457/283723fc-5ace-499e-8b36-22dfc88d1d3c">

이 알고리즘의 시간 복잡도는 위의 각 단계에 소요된 시간의 합이다. O(p) + O(c) + O(c log c)
이 알고리즘은 직관적이지만 최악의 경우 k개 결과를 얻기 위해 전체 트라이를 다 검색해야 할 수도 있다. 이걸 해결하려면 다음 두 가지를 고려한다.

1. 접두어의 최대 길이를 제한
2. 각 노드에 인기 검색어를 캐시

##### 접두어 최대 길이 제한

사용자가 검색창에 긴 검색어를 입력하는 일은 거의 없다. 따라서 p값은 작은 정수(50)라고 가정해도 된다.
검색어의 최대 길이를 제한할 수 있다면 "접두어 노드를 찾는" 단계의 시간 복잡도는 O(p)에서 O(작은 상수) = O(1)로 바뀔 것이다.

##### 노드에 인기 검색어 캐시

각 노드에 k개의 인기 검색어를 저장해 두면 전체 트라이를 검색하는 일을 방지할 수 있다. 5 ~ 10개의 자동완성 제안을 표시하면 충분하므로 k는 작은 값이다. 여기서는 5개의 질의를 캐시하는 거라고 가정한다.
각 노드에 인기 질의어를 캐시해 두면 'top 5' 검색어를 질의하는 시간 복잡도를 엄청나게 낮출 수 있다. 반면 각 노드마다 질의어를 저장할 공간이 많이 필요하게 된다는 단점도 있다. 빠른 응답속도가 아주 중요할 때는 이 정도 저장공간을 희생할 만한 가치는 있다.
아래 그림은 개선된 트라이 구조다. 각 노드에 인기 검색어 5개를 저장해 둔다.
예로 접두어 be를 나타내는 노드에는 [best: 35, bet: 29, bee: 20, be: 15, beer: 10]의 다섯 개의 검색어를 캐시해 둔 걸 볼 수 있다.

<img width="468" alt="image" src="https://github.com/jongfeel/BookReview/assets/17442457/a13e3e87-eb41-45d0-851c-bbac0a75ad79">

이 최적화 기법을 적용하면 시간 복잡도는 아래와 같이 달라진다.

1. 접두어 노드를 찾는 시간 복잡도는 O(1)로 바뀐다.
2. 최고 인기 검색어 5개를 찾는 질의의 시간 복잡도도 O(1)로 바뀐다. 검색 결과가 이미 캐시되어 있기 때문이다.

단계별 시간 복잡도가 O(1)로 바뀐 덕분에, 최고 인기 검색어 k개를 찾는 전체 알고리즘의 복잡도도 O(1)로 바뀌게 된다.

#### 데이터 수집 서비스

여태까지는 사용자가 검색창에 타이핑을 할 때마다 실시간 데이터를 가져오게 했는데 아래 두 가지 문제로 실용적이지 못한 방법이다.

- 매일 수천만건의 질의에 대해 트라이를 갱신하면 질의 서비스는 심각하게 느려질 것이다.
- 트라이가 만들어지고 난 이후 인기 검색어는 자주 바뀌지 않을 것이고, 그러면 트라이는 자주 갱신할 필요가 없다.

규모 확장이 쉬운 데이터 수집 서비스를 만들려면 데이터가 어디서 오고 어떻게 이용되는지 알아야 한다.
트위터 같은 경우는 제안되는 검색어를 최신 상태로 유지할 필요가 있지만, 구글 검색의 경우는 자주 바꿀 이유는 없게 된다.
용례가 달라져도 데이터 수집 서비스의 기본은 바뀌지 않을 것이다. 트라이를 만드는 데 쓰는 데이터는 보통 데이터 분석 서비스나 로깅 서비스로 부터 오기 때문이다.
아래 그림은 데이터 분석 서비스의 수정된 설계안이고 각 컴포넌트를 살펴볼 것이다.

<img width="467" alt="image" src="https://github.com/jongfeel/BookReview/assets/17442457/794930e3-2e2a-4ad5-9e2e-60d247d93eed">

##### 데이터 분석 서비스 로그

데이터 분석 서비스 로그는 검색창에 입력된 질의 원본 데이터를 보관한다.
새로운 데이터를 추가할 뿐 수정이 이루어 지지 않기 때문에 로그 데이터에는 인덱스를 걸지 않는다.
아래 표는 로그 파일 예제이다.

| query | time |
|-------|-------|
| tree | 2019-10-01 22:01:01 |
| try | 2019-10-01 22:01:05 |
| tree | 2019-10-01 22:01:30 |
| toy | 2019-10-01 22:02:22 |
| tree | 2019-10-01 22:02:42 |
| try | 2019-10-01 22:03:03 |

##### 로그 취합 서버

로그의 양이 많고 데이터 형식도 제각각인 경우가 많으면 이 데이터를 잘 취합해서(aggregation) 우리 시스템에서 쉽게 사용할 수 있게 해야 한다.
데이터를 취합하는 방식은 서비스의 용례에 따라 달라지는데, 트위터의 경우는 결과를 빨리 보여주는 것이 중요하므로 데이터 취합 주기를 짧게 가져갈 필요가 있다. 보통은 1주일에 한번 정도 로그 취합해도 충분할 수 있어서 데이터 취합의 실시간성이 얼마나 중요한지는 면접관과 확인하는게 좋다.
여기서는 1주일 주기로 취합하면 충분하다고 가정한다.

##### 취합된 데이터

아래 표는 매주 취합한 데이터의 사례이다. time 필드는 1주 단위에서의 시작 날짜이고, frequency는 1주간 사용한 횟수의 합이다.

| query | time | frequency |
|--------|------|------------|
| tree | 2019-01-01 | 12000 |
| tree | 2019-01-08 | 15000 |
| tree | 2019-10-15 | 9000 |
| toy | 2019-01-01 | 8500 |
| toy | 2019-01-08 | 6256 |
| toy | 2019-10-15 | 8866

##### 작업 서버

작업 서버는 주기적으로 비동기 작업을 실행하는 서버 집합이다.
트라이 자료구조를 만들고 트라이 데이터베이스에 저장하는 역할을 한다.

##### 트라이 캐시

트라이 캐시는 분산 캐시 시스템으로 트라이 데이터를 메모리에 유지하여 읽기 연산 성능을 높인다.
매주 트라이 데이터베이스의 스냅샷을 만들고 갱신한다.

##### 트라이 데이터베이스

트라이 데이터베이스는 지속성 저장소이다. 이 데이터베이스의 선택지로는 아래 두 가지가 있다.

1. 문서 저장소(document store): 새 트라이를 매주 만들 것이므로, 주기적으로 트라이를 직렬화하여 데이터베이스에 저장할 수 있다. MongoDB는 이런 데이터를 편리하게 저장할 수 있다.
2. 키-값 저장소: 트라이는 아래 로직을 적용해서 해시 테이블 형태로 변환할 수 있다.

- 트라이에 보관된 모든 접두어를 해시 테이블 키로 변환
- 각 트라이 노드에 보관된 모든 데이터를 해시 테이블 값으로 변환

아래 그림은 트라이를 해시 테이블로 어떻게 대응하는지 보여준다.

<img width="464" alt="image" src="https://github.com/jongfeel/BookReview/assets/17442457/1e08b930-b2e9-49a0-b944-412803e22d9e">

#### 질의 서비스

앞선 설계는 데이터베이스를 활용해서 인기 검색어 5개를 뽑았는데
해당 설계의 비효율성을 개선한 새로운 설계안이 아래 그림이다.

<img width="325" alt="image" src="https://github.com/jongfeel/BookReview/assets/17442457/21375fbd-1de8-4843-9325-be099ffac712">

1. 검색 질의가 로드밸런서로 전송
2. 로드 밸런서는 해당 질의를 API 서버로 전송
3. API 서버는 트라이 캐시에서 데이터를 가져와 해당 요청에 대한 자동 완성 검색어 제안 응답을 구성
4. 데이터가 캐시에 없다면 데이터베이스에서 가져오고 캐시에 채운다. 이렇게 해야 다음에 같은 접두어에 대한 질의에 대해 캐시에서 처리할 수 있다. 캐시 미스는 캐시 서버의 메모리가 부족하거나 장애가 있어도 발생할 수 있다.

질의 서비스는 빨라야 하므로 아래와 같은 최적화 방안을 고려해야 한다.

- AJAX 요청(request): 웹 어플리케이션에서 보통 ajax 요청을 보내서 자동 완성된 검색어 목록을 가져오는 방법을 쓴다. 이 방법을 쓰면 요청을 보내고 받는데 있어서 페이지 새로고침을 할 필요가 없다.
- 브라우저 캐싱(browser caching): 대부분 자동완성 검색어 제안 결과는 짧은 시간 안에 자주 바뀌지 않는다. 따라서 검색어들을 브라우저 캐시에 넣어두면 후속 질의의 결과는 해당 캐시에서 바로 가져갈 수 있다. 구글 검색 엔진은 이런 캐시 매커니즘을 사용한다. 아래 그림은 구글 검색 엔진에 system design interview라고 입력하면 볼 수 있는 응답 헤더이다. 구글은 검색어를 한 시간 동안 캐시를 해 둔다. cache-control 헤더 값의 private은 사용자의 캐시에만 보관할 수 있으며 공용 캐시에 보관하지 않는다는 뜻이다. max-age=3600은 3600초, 즉 한 시간 동안만 유효하다는 뜻이다.

<img width="467" alt="image" src="https://github.com/jongfeel/BookReview/assets/17442457/21db0f1f-89e4-4d8d-b9d2-cb13920a501e">

그런데 실제로 브라우저에서 해보면 cache-control의 값은 private, max-age=0 으로 보인다.

<img width="629" alt="image" src="https://github.com/jongfeel/BookReview/assets/17442457/34c234ba-e697-45c8-b8e8-7673a704baae">

- 데이터 샘플링(data sampling): 대규모 시스템의 경우, 모든 질의를 로깅해 놓으면 CPU 자원과 저장공간을 엄청나게 소진하게 된다. 이때 데이터 샘플링 기법을 적용하면 유용하다. N개 요청 가운데 1개만 로깅하도록 하는 것이다.

#### 트라이 연산

트라이는 검색어 자동완성 시스템의 핵심 컴포넌트이다. 트라이 관련 연산이 어떻게 동작하는지 살펴본다.

##### 트라이 생성

트라이 생성은 작업 서버가 담당하며, 데이터 분석 서비스의 로그나 데이터베이스로부터 취합된 데이터를 이용한다.

##### 트라이 갱신

1. 매주 한 번 갱신. 새로운 트라이를 만든 다음에 기존 트라이를 대체
2. 트라이의 각 노드를 개별적으로 갱신. 여기서는 이 방법을 채택하지 않았는데 이유는 성능이 좋지 않아서이다. 하지만 트라이가 작을 때는 고려해볼 만 하다. 트라이 노드를 갱신할 때는 그 상위 노드도 갱신해야 하는데, 상위 노드에도 인기 검색어의 질의 결과가 보관되기 때문이다. 아래 그림은 이 갱신 연산이 어떻게 동작하는지 보여준다.

<img width="458" alt="image" src="https://github.com/jongfeel/BookReview/assets/17442457/50b9590e-3393-4e7d-8cd5-47b96e3727d5">

왼쪽 트라이에서 검색어 'beer'의 이용 빈도를 10에서 30으로 갱신해야 한다고 하면, 오른쪽 트라이 처럼 30으로 바뀌게 된다. 그러면 해당 노드의 상위 노드들인 'bee', 'be', 'b'의 이용 빈도도 모두 30으로 갱신된다.

##### 검색어 삭제

혐오성, 폭력적, 성적 검색어의 경우는 자동완성 결과에서 제거해야 한다. 이 방법에는 아래 그림과 같이 트라이 캐시 앞에 필터 계층을 두고 부적절한 질의어가 반환되지 않도록 한다. 필터 계층을 통해 검색 결과를 자유롭게 변경할 수 있다는 장점이 있다. 데이터베이스에서 해당 검색어를 삭제하는 건 다음 업데이트 때 비동기적으로 진행하면 된다.

<img width="467" alt="image" src="https://github.com/jongfeel/BookReview/assets/17442457/465cdf03-9249-41bc-a5c8-1737baa3297e">

#### 저장소 규모 확장

트라이의 크기가 한 서버에 넣기에 너무 큰 경우에 대응할 수 있도록 규모 확장성 문제를 해결해 본다.
영어 기준으로 지원하므로 첫 글자를 기준으로 샤딩을 진행한다. 아래가 그 예제이다.

- 검색어를 보관하기 위해 서버를 두대 쓴다면, 'a'부터 'm'까지 시작하는 검색어는 서버1에, 나머지는 서버2에 저장한다.
- 세 대라면 'a'부터 'i'까지가 서버1, 'j'부터 'r'까지를 서버2, 나머지를 서버3에 저장한다.

이렇게 하면 가능한 서버의 대수는 26대가 되는데 영어 알파벳이 26글자이기 때문이다. 이 이상으로 서버 대수를 늘리려면 샤등을 계층적으로 해야 한다. 'a'로 시작하는 검색어를 네 대의 서버로 나눠 보관한다면 두 번째 글자 기준으로 샤딩을 진행한다. 즉, 'aa'부터 'ag'까지가 서버1, 'ah'부터 'an'까지는 서버2, 'ao'부터 'au'는 서버3, 나머지를 서버4에 보관하는 식이다.
하지만 'c로 시작하는 단어가 'x'로 시작하는 단어보다 많으므로 데이터가 각 서버에 균등하게 들어가지는 않는다.
이 문제를 해결하려면 과거 질의 데이터 패턴을 분석해서 샤딩하는 아래 그림과 같은 설계가 필요하다.

<img width="396" alt="image" src="https://github.com/jongfeel/BookReview/assets/17442457/8ee7f94e-92d3-4cf9-95e6-56a8b7e587cb">

검색어 대응 샤드 관리자(shard map manager)는 어떤 검색어가 어느 저장소 서버에 저장되는지에 대한 정보를 관리한다.
예로 's'로 시작하는 검색어의 양이 'u', 'v', 'w', 'x', 'y', 'z'로 시작하는 검색어 전부를 합친 것과 비슷하다면, 's'에 대한 샤드 하나와 'u'부터 'z'까지의 검색어를 위한 샤드 하나를 둬도 충분하다.

### 4단계 마무리

상세 설계 이후 면접관과 다음의 질문들을 받을 수 있다.

> 다국어 지원이 가능하도록 시스템을 확장하려면 어떻게 해야 할까요?

트라이에 유니코드 데이터를 저장해야 한다. 유니코드는 세상에 존재하는 모든 문제 체계를 지원하는 표준 인코딩 시스템이다.

> 국가별로 인기 검색어 순위가 다르다면 어떻게 해야 하나요?

국가별로 다른 트라이를 사용한다. 트라이를 CDN에 저장해서 응답속도를 높이는 방법도 고려한다.

> 실시간으로 변하는 검색어 추이를 반영하려면 어떻게 해야 하나요?

새로운 뉴스 이벤트로 특정 검색어의 인기가 갑자기 높아질 수 있다.
여기서 설계한 것으로는 그런 검색어를 지원하기에 적합하지 않은데 그 이유는

- 작업 서버가 매주 한 번씩만 돌도록 되어 있어서 실시간 성으로 트라이를 갱신할 수 없다.
- 실시간 성을 반영한다고 해도, 트라이를 구성하는 데 너무 많은 시간이 소요된다.

실시간 검색어 자동완성 시스템은 이 설계의 범위를 벗어나지만 아래 아이디어를 고려해 볼 수 있다.

- 샤딩을 통해 작업 대상 데이터의 양을 줄인다.
- 순위 모델(ranking model)을 바꿔 최근 검색어에 보다 높은 가중치를 주도록 한다.
- 데이터가 스트림 형태, 즉 한번에 모든 데이터를 동시에 사용할 수 없는 가능성도 고려해야 한다. 데이터가 스트림 형태라는 건 지속적으로 생성된다는 뜻이므로 이런 프로세싱을 위해서는 특별한 종류의 시스템이 필요하다. 
  - Apache Hadoop MapReduce
  - Apache Spark Streaming
  - Apache Storm
  - Apache Kafka