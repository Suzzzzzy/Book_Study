## CHAPTER 15: DESIGN GOOGLE DRIVE

```
논의내용)
블록 서버 저장소라는 걸 거치지 않고 바로 S3에 업로드 하는 걸 생각했는데 마지막에 그러면 안된다고 알려줘서 논의 주제가 없어졌습니다.

그리고 또 하나 배운건 메타데이터 처리 API와 실제 파일 업로드 API를 분리해서 병렬로 처리하는게 좋은 방법일 거라는 생각을 했습니다.
```

구글 드라이브는 파일 저장 및 동기화 서비스로 문서, 사진, 비디오, 기타 파일을 클라우드에 보관할 수 있다.
이 파일들은 컴퓨터, 스마트폰, 태블릿 등 어떤 단말에서도 이용 가능해야 한다.
또 파일들은 친구, 가족, 동료들과 손쉽게 공유할 수 있어야 한다.

<img width="408" alt="image" src="https://github.com/jongfeel/BookReview/assets/17442457/17f81de7-5ef0-4293-a4b9-5d7772da302c">

<img width="160" alt="image" src="https://github.com/jongfeel/BookReview/assets/17442457/5764e659-b4fa-4db4-84e0-d9dd78ae8cb3">

### 문제 이해 및 설계 범위 확정

구글 드라이브를 설계하는 건 큰 프로젝트이므로 면접관과 질문을 통해 설계 범위를 좁혀야 한다.

여기서는 다음 기능의 설계에 집중한다.

- 파일 추가, 가장 쉬운 방법으로 파일을 구글 드라이브 안으로 떨구는(drag-and-drop) 것이다.
- 파일 다운로드
- 여러 단말에 파일 동기화, 한 단말에서 파일을 추가하면 다른 단말에서 자동으로 동기화
- 파일 갱신 이력 조회(revision)
- 파일 공유
- 파일이 편집되거나 삭제되거나 새롭게 공유되었을 때 알림 표시

논의하지 않는 기능은 다음과 같다.

- 구글 문서 편집 및 협업 기능, 여러 사용자가 같은 문서를 동시에 편집하는 기능이 있는데 설계 범위에서 제외한다.

비기능적 요구사항은 다음과 같다.

- 안정성: 저장소 시스템에서는 매우 중요하다. 데이터 손실이 일어나면 안된다.
- 빠른 동기화 속도: 파일 동기화에 시간이 걸리면 사용자가 오래 기다려주지 않고 서비스를 사용하지 않게 된다.
- 네트워크 대역폭: 모바일 데이터 등의 네트워크 대역폭을 불필요하게 많이 소모한다면 좋아하지 않을 것이다.
- 규모 확장성: 아주 많은 양의 트래픽도 처리 가능해야 한다.
- 높은 가용성: 서버에 장애가 발생해서 느려지거나 네트워크 일부가 끊겨도 시스템은 계속 사용 가능해야 한다.

#### 개략적 추정치

- 가입 사용자는 5천만명이고, DAU는천만명이다.
- 모든 사용자에게 10GB의 무료 저장공간 할당
- 사용자는 매일 평균 2개의 파일을 업로드한다고 가정, 각 파일의 평균 크기는 500KB
- 읽기/쓰기 비율은 1:1
- 필요한 저장공간 총량 = 5천만 사용자 x 10GB = 500PB
- 업로드 API QPS = 천만 사용자 x 2회 업로드 / 24시간 / 3600초 = 약 240
- 최대 QPS = QPS x 2 = 480

### 2단계 개략적 설계안 제시 및 동의 구하기

모든 것을 담은 한 대의 서버를 만들고 점진적으로 천만 사용자 지원이 가능한 시스템으로 발전시켜 본다.
이렇게 진행하면 앞에서 다룬 기술들이 필요하다는 걸 알게 된다.

아래와 같은 구성의 서버 한 대로 시작해 본다.

- 파일을 올리고 다운로드 하는 과정을 처리하는 웹 서버
- 사용자 데이터, 로그인 정보, 파일 정보 등의 메타데이터를 보관할 데이터베이스
- 파일을 저장할 저장소 시스템, 파일 저장을 위해 1TB 공간을 사용

웹 서버는 apache로 하고 MySQL도 설치한다. 업로드한 파일을 저장하는 경로는 drive/ 로 한다. drive/ 디렉터리에는 네임스페이스라고 부르는 하위 디렉터리들을 둔다. 각 네임스페이스 안에 특정 사용자가 올린 파일을 이름 그대로 보관한다. 각 파일과 폴더는 네임스페이스 이름과 결합하면 유일하게 식별할 수 있다.
아래 그림은 drive/ 디렉터리에 실제 파일이 보관된 사례이다.

<img width="379" alt="image" src="https://github.com/jongfeel/BookReview/assets/17442457/19e71e63-7490-479d-8bf5-b0500ee5fb3c">

#### API

##### 1. 파일 업로드 API

업로드는 두 가지 종류를 지원한다.

- 단순 업로드: 파일 크기가 작을 때 사용
- 이어 올리기(resumable upload): 파일 사이즈가 크고 네트워크 문제로 업로드가 중단될 가능성이 높다고 생각될 때 사용

이어 올리기 API 예:
*https://api.example.com/files/upload?uploadType=resumable*

Params:

- uploadType=resumable
- data: 업로드할 로컬 파일

이어 올리기는 다음 세 단계 절차로 이루어진다.

- 이어 올리기 URL을 받기 위한 최초 요청 전송
- 데이터를 업로드하고 업로드 상태 모니터링
- 업로드에 장애가 발생하면 장애 발생시점부터 업로드를 재시작

##### 2. 파일 다운로드 API

예: *https://api.example.com/files/download*

Params:

- path: 다운로드할 파일의 경로

```
{
    "path": "/recipes/soup/best_soup.txt"
}
```

#### 3. 파일 갱신 히스토리 API

예: *https://api.example.com/files/list_revisions*

Params:

- path: 갱신 히스토리를 가져올 파일의 경로
- limit: 히스토리 길이의 최대치

```
{
    "path": "/recipes/soup/best_soup.txt",
    "limit": 20
}
```

모든 API는 사용자 인증을 해야 하고 https 프로토콜을 사용한다. SSL(Secure Socket Layer)를 지원하는 프로토콜을 이용하는 이유는 클라이언트와 백엔드 서버가 주고받는 데이터를 보호하기 위함이다.

#### 한 대 서버의 제약 극복

업로드 하는 파일이 많아지면 결국 파일 시스템은 가득 찬다.

<img width="288" alt="image" src="https://github.com/jongfeel/BookReview/assets/17442457/608acda6-75b6-4bcc-a2f0-a2ffb3a738d4">

이런 상태면 더 이상 파일 업로드가 불가능하므로 문제를 해결해야 하는데 샤딩을 통해 여러 서버에 나눠서 저장한다.
아래 그림은 user_id를 기준으로 샤딩한 예이다.

<img width="303" alt="image" src="https://github.com/jongfeel/BookReview/assets/17442457/a38eba6d-1ae7-46e1-8a23-94919f28f8c0">

급한 불은 껐지만 서버 장애가 또 일어난다면 문제가 된다.
아마존 S3는 객체 저장소 서비스로, 여러 자료를 검토한 결과 S3를 사용하기로 결정한다.
S3는 같은 지역 안에서도 다중화가 가능하고 여러 지역에 걸쳐 다중화를 할 수도 있다.
아래 왼쪽 그림처럼 같은 지역에서 다중화가 되고, 오른쪽 그림처럼 여러 지역에 걸쳐서 할 수도 있다.
보통 여러 지역에 걸쳐서 다중화하는게 데이터 손실을 막고 가용성을 최대한 보장할 수 있다.
버킷은 파일 시스템의 폴더와 같다.

<img width="454" alt="image" src="https://github.com/jongfeel/BookReview/assets/17442457/459e077a-e51d-456a-83bc-96221b91b27c">

미래에 문제가 생기는 걸 막기 위해 더 개선할 부문을 찾아 본다.

- 로드밸런서: 네트워크 트래픽 분산을 위해 로드밸런서를 사용
- 웹 서버: 로드밸런서 추가 후에 더 많은 웹 서버를 손쉽게 추가할 수 있다.
- 메타데이터 데이터베이스: 데이터베이스를 파일 저장 서버와 분리하여 SPOF(Single Point of Failure)를 피한다. 다중화와 샤딩을 적용해서 가용성 및 규모 확장성에 대응한다.
- 파일 저장소: S3를 파일 저장소로 사용하고 가용성과 데이터 무손실을 보장하기 위해 두 개 이상의 지역에 데이터를 다중화한다.

이제 한 대의 서버에서 여러 서버로 분리가 되었고 아래 그림이 수정된 설계안이다.

<img width="303" alt="image" src="https://github.com/jongfeel/BookReview/assets/17442457/387bcb9a-1b05-4677-9140-71908f27b32a">

#### 동기화 충돌

두 명 이상의 사용자가 같은 파일이나 폴더를 동시에 업데이트 하려고 하면 동기화 충돌이 발생한다.
여기서는 먼저 처리되는 변경이 성공이고, 나중에 처리되는 변경은 충돌이 발생한 것으로 표시한다.

<img width="470" alt="image" src="https://github.com/jongfeel/BookReview/assets/17442457/16024c27-d9aa-4417-8ae0-4f12ca646232">

이 오류가 발생한 시점에는 같은 파일의 두 가지 버전이 존재한다.
아래 그림과 같이 사용자2가 가지고 있는 로컬 사본과 서버에 있는 최신 버전이다. 사용자는 두 파일을 하나로 합치던가 둘 중 한 파일을 다른 파일로 대체해야 한다.

<img width="421" alt="image" src="https://github.com/jongfeel/BookReview/assets/17442457/a56f4244-f567-481f-bedc-721173e40318">

#### 개략적 설계안

<img width="430" alt="image" src="https://github.com/jongfeel/BookReview/assets/17442457/9e165c4f-bb70-417e-a0db-f7fc3a08b017">

- 사용자: 웹브라우저 혹은 모바일 앱
- 블록 서버: 파일 블록을 클라우드 저장소에 업로드하는 서버. 블록 저장소는 블록 수준 저장소(block-level storage)라고 하며 클라우드 환경에서 데이터 파일을 저장하는 기술이다. 이 저장소는 파일을 여러 개의 블록으로 나눠서 저장하며, 각 블록에는 고유한 해시값이 할당된다. 이 해시값은 메타데이터 데이터베이스에 저장된다. 각 블록은 독립 객체이며 클라우드 저장소인 S3에 보관된다. 파일을 재구성하려면 블록들을 원래 순서대로 합쳐야 한다. 이 설계안의 경우 한 블록은 드롭박스의 사례를 따라 4MB로 정한다.
- 클라우드 저장소: 파일은 블록 단위로 나눠져서 클라우드 저장소에 보관한다.
- 아카이빙 저장소(Cold storage): 오랫동안 사용하지 않은 비활성 데이터를 저장한다.
- 로드밸런서: 요청을 모든 API 서버에 고르고 분산한다.
- API 서버: 파일 업로드 이외의 기능을 담당한다. 사용자 인증, 사용자 프로파일, 파일 메타데이터 갱신 등
- 메타데이터 데이터베이스: 사용자, 파일, 블록, 버전 등의 메타데이터 정보를 관리한다. 실제 파일은 클라우드에 있으며 이 데이터베이스는 메타데이터만 저장한다.
- 메타데이터 캐시: 성능을 높이기 위해 자주 쓰는 메타데이터는 캐시한다.
- 알림 서비스: 이벤트 발생 시 클라이언트에게 알려주는 발행/구독 프로토콜 기반 시스템이다. 파일 추가/편집/삭제 시 알림을 줘서 파일의 최신 상태를 확인하는데 쓴다.
- 오프라인 백업 큐: 클라이언트가 접속 중이 아니거나 파일의 최신 상태를 확인할 수 없다면, 해당 정보를 큐에 넣고 나중에 클라이언트가 접속하면 동기화 시키는 역할

### 3장 상세 설계

#### 블록 저장소 서버

정기적으로 갱신되는 큰 파일은 업데이트를 할 때 마다 전체 파일을 서버로 보내면 네트워크 대역폭을 많이 쓰게 된다.
이를 최적화하는 방법으로 아래 두 가지를 생각해 볼 수 있다.

- 델타 동기화(delta sync): 파일이 수정되면 전체 파일 대신 수정이 일어난 블록만 동기화
- 압축(Comporession): 블록 단위로 압축해 두면 데이터 크기를 많이 줄일 수 있다. 파일 유형에 따라 압축 알고리즘을 정해서 쓰며 텍스트 파일은 gzip bzip2, 이미지나 비디오는 다른 알고리즘을 쓴다.

블록 저장소 서버는 클라이언트가 보낸 파일을 블록 단위로 나누고, 각 블록에 압축 알고리즘을 적용하고 암호화까지 해야 한다. 전체 파일을 저장소 시스템으로 배는 대신 수정된 블록만 전송해야 한다.
새 파일이 추가되면 블록 저장소는 아래 그림과 같이 동작한다.

<img width="462" alt="image" src="https://github.com/jongfeel/BookReview/assets/17442457/c0e13580-5bff-45b6-ab98-9660dad07d3d">

- 주어진 파일을 작은 블록들로 분할한다.
- 각 블록을 압축한다.
- 암호화를 한다.
- 클라우드 저장소로 보낸다.

아래 그림은 델타 동기화 전략이 어떻게 동작하는지를 보여준다. 갱신된 부분만 동기화가 진행되어야 하므로 검정색으로 표시된 블록2, 블록5만 클라우드 저장소에 업로드 한다.

<img width="398" alt="image" src="https://github.com/jongfeel/BookReview/assets/17442457/58122698-6c34-4949-a4a0-256d31f211a9">

블록 저장소 서버에 델타 동기화 전략과 압축 알고리즘을 사용하면 네트워크 대역폭 사용량을 절감할 수 있다. 

#### 높은 일관성 요구사항

이 시스템은 같은 파일이 단말이나 사용자에 따라 다르게 보이면 안되는 강한 일관성(strong consistency) 모델을 기본으로 지원해야 한다. 메타데이터 캐시와 데이터베이스 계층에도 같은 원칙이 적용되어야 한다.
메모리 캐시는 최종 일관성(eventual consistency) 모델을 지원한다. 강한 일관성을 달성하기 위해 다음 내용을 보장해야 한다.

- 캐시에 보관된 사본과 데이터베이스에 있는 원본이 일치
- 데이터베이스에 보관된 원본에 변경이 발생하면 캐시에 있는 사본을 무효화

관계형 데이터베이스는 ACID(Atomicity, Consistency, Isolation, Durability)를 보장하므로 강한 일관성을 보장하기 쉽다.
NoSQL 데이터베이스는 이를 지원하지 않으므로 동기화 로직 안에 프로그램해서 넣어야 한다.
여기서는 ACID를 기본 지원하는 관계형 데이터베이스를 채택해서 높은 일관성 요구사항에 대응한다.

#### 메타데이터 데이터베이스

아래 데이터베이스 스키마는 중요한 것만 간추렸고 단순화한 형태를 보여준다.

<img width="464" alt="image" src="https://github.com/jongfeel/BookReview/assets/17442457/3f5345e6-7bc5-4cd8-ba41-642e6f2ee027">

- user: 이름, 이메일, 프로파일 사진 등 사용자 정보 저장
- device: 단말 정보 저장, 한 사용자는 여러 대의 단말을 가질 수 있다.
- namespace: 사용자의 루트 디렉터리 정보 보관
- file: 파일의 최신 정보를 보관
- file_version: 파일의 갱신 이력이 보관되는 테이블, 읽기 전용으로 갱신 이력이 훼손되는 것을 막는다.
- block: 파일 블록에 대한 정보를 보관. 특정 버전의 파일은 파일 블록을 올바른 순서로 조합하면 복원할 수 있다.

#### 업로드 절차

아래 그림은 두 요청이 병렬적으로 일어나는 상황을 보여주는 시퀀스 다이어그램이다.
첫 번째 요청은 파일 메타데이터를 추가하기 위한 것이고
두 번째 요청은 파일을 클라우드 저장소로 업로드하기 위한 것이다.
이 두 요청은 클라이언트 1이 보낸 것이다.

<img width="469" alt="image" src="https://github.com/jongfeel/BookReview/assets/17442457/c6e26ef4-9475-4197-a7c1-9e6a9c9a4126">

파일 메타데이터 추가

1. 클라이언트 1이 새 파일의 메타데이터를 추가하기 위해 요청 전송
2. 새 파일의 메타데이터를 데이터베이스에 저장하고 업로드 상태를 대기중(pending)으로 변경
3. 새 파일이 추가되었음을 알림 서비스에 통지
4. 알림 서비스는 관련된 클라이언트2에게 파일이 업로드되고 있음을 알림

파일을 클라우드 저장소에 업로드

2.1 클라이언트 1이 파일을 블록 저장소 서버에 업로드
2.2 블록 저장소 서버는 파일을 블록 단위로 쪼갠 다음 압축하고 암호화한 다음에 클라우드 저장소에 전송
2.3 업로드가 끝나면 클라우드 스토리지는 완료 콜백(callback)을 호출, 이 콜백은 API 서버로 전송됨
2.4 메타데이터 DB에 기록된 해당 파일의 상태를 완료로 변경
2.5 알리 ㅁ서비스에 파일 업로드가 끝났음을 통지
2.6 알림 서비스는 클라이언트2에게 파일 업로드가 끝났음을 알림

파일 수정도 유사한 흐름으로 진행된다.

#### 다운로드 절차

파일 다운로든느 파일이 새로 추가되거나 편집되면 자동으로 시작된다.
한 클라이언트는 다른 클라이언트가 파일을 편집하거나 추가했다는 사실을 아래 두 가지 방법을 사용해서 알아낸다.

- 클라이언트 A가 접속중이고 다른 클라이언트가 파일을 변경하면 알림 서비스가 클라이언트 A에게 변경이 발생했으니 새 버전을 가져와야 한다고 알린다
- 클라이언트 A가 네트워크에 연결된 상태가 아닐 경우 데이터는 캐시에 보관된다. 해당 클라이언트가 접속 중으로 바뀌면 그때 해당 클라이언트는 새 버전을 가져간다.

아래 그림은 파일이 변경된 걸 감지한 클라이언트가 API 서버를 통해 메타데이터를 새로 가져오고, 그 다음에 블록들을 다운받아서 파일을 재구성해야 하는 흐름을 보여준다.

<img width="466" alt="image" src="https://github.com/jongfeel/BookReview/assets/17442457/43c8aabf-1ef6-469c-a988-6a79c2444ea4">

1. 알림 서비스가 클라이언트 2에게 파일이 변경된 걸 알림
2. 클라이언트 2는 메타데이터를 요청
3. API 서버는 메타데이터 데이터베이스에게 변경된 메타데이터 요청
4. API 서버에 메타데이터 반환
5. 클라이언트 2는 메타데이터를 얻음
6. 클라이언트 2는 블록을 다운로드 받기 위해 블록 서버에 전송 요청
7. 블록 서버는 클라우드 저장소에서 블록 다운로드
8. 클라우드 저장소는 블록 서버에 블록 전달
9. 클라이언트2는 파일 재구성을 위해 새 블록을 다운로드

#### 알림 서비스

알림 서비스는 파일 일관성 유지를 위해 로컬 파일이 수정된 걸 다른 클라이언트에 알려서 충돌 가능성을 줄인다.
단순하게 보면 알림 서비스는 이벤트 데이터를 클라이언트들로 보내는 서비스로 다음 두 가지의 선택지가 있다.

- 롱 폴링: 드롭박스가 채택
- 웹 소켓: 클라이언트와 서버의 지속적 연결을 통해 양방향 통신이 가능

여기서는 롱 폴링을 사용하는데 이유는 다음과 같다.

- 채팅 서비스가 아니므로 알림 서비스의 양방향 통신이 필요하지 않다. 서버는 파일이 변경된 사실을 클라이언트에게 알려주지만 반대 방향의 통신은 요구되지 않는다.
- 웹 소켓은 실시간 양방향 통신이 요구되는 채팅 같은 서비스에 적합하다. 구글 드라이브의 경우 알림을 보낸 일은 그렇게 자주 발생하지 않으며 알림을 보내는 경우에도 단시간에 많은 양의 데이터를 보내지 않는다.

롱 폴링을 쓰면 각 클라이언트는 알림 서버와 롱 폴링 연결을 유지하다가 특정 파일의 변경을 감지하면 해당 연결을 끊는다.
이때 클라이언트는 메타데이터 서버와 연결해서 파일의 최신 내역을 다운로드 해야 한다.
해당 다운로드 작업이 끝나거나 타임아웃 시간에 도달하면 다시 롱 폴링 연결을 복원하고 유지한다.

#### 저장소 공간 절약

파일 갱신 이력을 보존하고 안정성을 보장하기 위해 파일의 여러 버전을 여러 데이터센터에 보관해야 한다.
모든 버전을 자주 백업하게 되면 저장용량이 빨리 소진될 가능성이 높다.
이런 문제를 피하고 비용 절감을 위해 아래 세 가지 방법을 사용한다.

- 중복 제거(de-dupe): 중복된 파일 블록을 계정 차원에서 제거하는 방법. 두 블록이 같은 블록인지는 해시 값을 비교해서 판단한다.
- 지능적 백업 전략을 도입한다.
  - 한도 설정: 보관해야 하는 파일 버전 개수에 상한을 둔다. 상한에 도달하면 제일 오래된 버전은 버린다.
  - 중요한 버전만 보관: 어떤 파일은 아주 자주 바뀌는데 편집중인 문서라면 짧은 시간에 1000개가 넘는 버전이 만들어질 수도 있다. 불필요한 버전과 사본이 만들어지는 걸 피하려면 중요한 것만 골라낸다.
- 자주 쓰이지 않는 데이터는 아카이빙 저장소(cold storage)로 옮긴다. 몇 달 혹은 수년 간 사용하지 않은 데이터이다. 아마존 S3 글래시어 같은 아카이빙 저장소는 S3보다 더 저렴하다.

#### 장애 처리

- 로드밸런서 장애: 로드밸런서도 여러개 둬서 한 로드밸런서가 장애가 발생하면 다른 로드밸런서로 대체한다. 로드밸런서끼리 박동(heartbeat) 신호를 주기적으로 보내 상태를 모니터링 한다.
- 블록 저장소 서버 장애: 다른 서버가 미완료 상태 또는 대기 상태인 작업을 이어받아야 한다.
- 클라우드 저장소 장애: S3 버킷은 여러 지역에 다중화하므로, 한 지역에서 장애가 일어나면 다른 지역에서 가져온다.
- API 서버 장애: API 서버들은 무상태 서버이므로 로드밸런서가 API 사버에 장애가 발생하면 트래픽을 해당 서버로 보내지 않는다.
- 메타데이터 캐시 장애: 메타데이터 캐시 서버도 다중화하므로 한 노드에 장애가 생겨도 다른 노드에서 데이터를 가져올 수 있다. 장애가 발생한 서버는 새 서버로 교체한다.
- 메타데이터 데이터베이스 장애
  - 주 데이터베이스 서버 장애: 부 데이터베이스 서버 중에 하나를 주 데이터베이스로 바꾸고, 부 데이터베이스 서버를 하나 추가한다.
  - 부 데이터베이스 서버 장애: 다른 부 데이터베이스 서버가 읽기 연산을 처리하도록 하고 그 동안 장애 서버는 새로 교체한다.
- 알림 서비스 장애: 접속 중인 모든 사용자는 알림 서버와 롱 폴링 연결을 하나씩 유지하므로 알림 서비스는 많은 사용자와 연결을 유지하고 관리해야 한다. 2012년 드롭박스는 알림 서비스 서버 한 대로 100만개의 연결을 유지했다. 여기서 장애가 발생하면 100만명 사용자의 롱 폴링 연결을 다시 만들어야 한다. 주의할 건 100만개 연결 유지는 가능하지만 동시에 100만개 연결 시작은 불가능하다. 따라서 롱 폴링 연결을 복구하는 건 상대적으로 느릴 수 있다.
- 오프라인 사용자 백업 큐 장애: 다중화해 둔다. 큐에 장애가 발생하면 구독 중인 클라이언트들은 백업 큐로 구독 관계를 재설정해야 한다.

### 4단계 마무리

설계안의 다른 선택지에 대해 논의해 보면 좋다.
예로 블록 저장소 서버를 거치지 않고 파일을 클라우드 저장소에 직접 업로드 하면 업로드 시간이 빨라지는 장점이 생기지만 몇 가지 단점도 생긴다.

- 분할, 압축, 암호화로직을 클라이언트에 두어야 하므로 플랫폼별로 따로 구현해야 한다. 원래 설계안은 이것들을 블록 저장소 서버라는 곳에 모아 뒀다.
- 클라이언트가 해킹 당할 수 있기 때문에 암호화 로직을 클라이언트 안에 두는 건 적절하지 않은 선택이다.

다른 예로, 접속상태를 관리하는 로직을 별도 서비스로 옮기는 것도 있다. 그러면 다른 서비스에서도 사용할 수 있는 독립적인 모듈이 된다. 